import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Model
from keras.layers import LSTM, Dense, Input, Concatenate, LayerNormalization
from keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import mean_squared_error
from math import sqrt
from keras.models import Sequential
from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM
import math
from sklearn.model_selection import TimeSeriesSplit
# 设置中文显示
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# 加载数据
bfgfasheng_data = pd.read_csv(r'E:\新建文件夹\代码\lstm\data\BFG\BFGFSL.csv')
fengya_data = pd.read_csv(r'E:\新建文件夹\代码\lstm\data\BFG\FengYa.csv')
fl_data = pd.read_csv(r'E:\新建文件夹\代码\lstm\data\BFG\FL.csv')
fy_data = pd.read_csv(r'E:\新建文件夹\代码\lstm\data\BFG\FY.csv')
xiaohao_data = pd.read_csv(r'E:\新建文件夹\代码\lstm\data\BFG\热风炉消耗BFG.csv')

# 提取特征列
bfgfasheng = bfgfasheng_data["value"][1:5000]
fengya = fengya_data["value"][1:5000]
fl = fl_data["value"][1:5000]
fy = fy_data["value"][1:5000]
xiaohao = xiaohao_data["value"][1:5000]
time = xiaohao_data["datetime"]

# 数据准备
scaler = MinMaxScaler()
fengya = scaler.fit_transform(fengya.values.reshape(-1, 1))
fl = scaler.fit_transform(fl.values.reshape(-1, 1))
fy = scaler.fit_transform(fy.values.reshape(-1, 1))

xiaohao = scaler.fit_transform(xiaohao.values.reshape(-1, 1))
scaler_bfgfasheng = MinMaxScaler() # 专门用于bfgfasheng的反归一化
bfgfasheng = scaler_bfgfasheng.fit_transform(bfgfasheng.values.reshape(-1, 1))

# 创建序列
sequence_length = 90  # 输入序列的长度
output_length = 30  # 输出序列的长度
X, y = [], []
for i in range(len(xiaohao) - sequence_length - output_length):
    X.append(np.c_[xiaohao[i:i+sequence_length], fengya[i:i+sequence_length], fl[i:i+sequence_length], fy[i:i+sequence_length]])
    y.append(bfgfasheng[i+sequence_length:i+sequence_length+output_length])

X, y = np.array(X), np.array(y)
# 训练集和测试集划分
split = 0.8
split_index = int(len(X) * split)
X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]
# 伪代码：FA优化函数

def euclidean_distance(x, y):
    return np.sqrt(np.sum((x - y) ** 2))


def attractiveness(beta0, gamma, distance):
    return beta0 * np.exp(-gamma * (distance ** 2))


# FA算法主体函数

def firefly_algorithm(objective_func, lower_bound, upper_bound, dim, n_fireflies=10, max_gen=100, alpha=0.5, beta0=1,
                      gamma=1):
    # 初始化萤火虫位置
    fireflies = np.random.uniform(low=lower_bound, high=upper_bound, size=(n_fireflies, dim))
    light_intensity = np.array([objective_func(firefly) for firefly in fireflies])

    # 初始化最优解
    best_firefly = fireflies[np.argmin(light_intensity)]
    best_intensity = np.min(light_intensity)

    # 迭代优化
    for gen in range(max_gen):
        for i in range(n_fireflies):
            for j in range(n_fireflies):
                # 如果发现更亮的萤火虫，则向它移动
                if light_intensity[j] < light_intensity[i]:  # 最小化问题，寻找更小的光强度
                    distance = euclidean_distance(fireflies[i], fireflies[j])
                    beta = attractiveness(beta0, gamma, distance)
                    fireflies[i] += beta * (fireflies[j] - fireflies[i]) + alpha * (np.random.rand(dim) - 0.5)
                    fireflies[i] = np.clip(fireflies[i], lower_bound, upper_bound)  # 保持在边界内

                    # 评估新的解并更新光强
                    new_intensity = objective_func(fireflies[i])
                    if new_intensity < light_intensity[i]:
                        light_intensity[i] = new_intensity

                        # 如果当前解更好，更新最优解
                        if new_intensity < best_intensity:
                            best_intensity = new_intensity
                            best_firefly = fireflies[i]

        # 随机化步长alpha，可以是固定的或者随着迭代次数减小
        alpha *= 0.97  # 例如，每次迭代步长减小3%

    return best_firefly
# LSTM模型构建函数
def build_lstm_model(input_shape, units):
    model = Sequential()
    model.add(LSTM(units=units, input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model
# 重构数据为LSTM期望的3D格式
# 重构数据为LSTM期望的3D格式
def create_dataset(X, y, time_window):
    Xs, ys = [], []
    for i in range(len(X) - time_window):
        Xs.append(X[i:(i + time_window)])
        ys.append(y[i + time_window])
    return np.array(Xs), np.array(ys)
def lstm_objective(params):
    # 解包参数
    time_window, batch_size, hidden_units = map(int, params)

    X_train_reshaped, y_train_reshaped = create_dataset(X_train, y_train, time_window)
    X_test_reshaped, y_test_reshaped = create_dataset(X_test, y_test, time_window)

    # 构建LSTM模型
    model = build_lstm_model(input_shape=(time_window, X_train_reshaped.shape[2]), units=hidden_units)

    # 使用TimeSeriesSplit进行时间序列的交叉验证
    tscv = TimeSeriesSplit(n_splits=5)
    cvscores = []

    for train_index, val_index in tscv.split(X_train_reshaped):
        # 训练并验证模型
        X_cv_train, X_cv_val = X_train_reshaped[train_index], X_train_reshaped[val_index]
        y_cv_train, y_cv_val = y_train_reshaped[train_index], y_train_reshaped[val_index]
        print("X_cv_train shape:", X_cv_train.shape)
        print("y_cv_train shape:", y_cv_train.shape)
        model.fit(X_cv_train, y_cv_train, epochs=50, batch_size=batch_size, verbose=0)
        y_pred = model.predict(X_cv_val)
        mse = mean_squared_error(y_cv_val, y_pred)
        cvscores.append(mse)

    # 计算交叉验证得分的平均值
    mean_mse = np.mean(cvscores)
    return mean_mse

# 定义超参数的搜索范围
lower_bound = [1, 32, 10]  # 最小时间窗口，最小批量大小，最少单元数
upper_bound = [10, 128, 100]  # 最大时间窗口，最大批量大小，最多单元数
dim = 3  # 优化维度

# 使用FA寻找最优超参数
best_params = firefly_algorithm(
    lstm_objective,
    lower_bound=lower_bound,
    upper_bound=upper_bound,
    dim=dim
)